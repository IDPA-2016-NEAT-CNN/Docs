We learned in the presentation of Dr. Krause at the SGAICO Annual Meeting and Workshop - Deep Learning and Beyond in Luzern of the concept of safety constraints. \\
He offered insight into his current studies about how to train system that have influence over real life and can cause harm. Examples where:
\begin{itemize}
	\item{A quadcopter learning to fly around a stationary object. It could potentially fly in a manner resulting in a crash, damaging itself or propriety, causing financial damage.}
	\item{A system learning how to apply a new experimental treatment to patients. This can end in life threatening circumstances.}
\end{itemize} 

A big point to consider here is the bayesian concept of false positives vs false negatives. In other words: "What is more critical, telling a patient he is sick when he is not (false positive) or telling him he is fine when he is actually pretty ill (false negative)?"\\
Of course, the answer to that depends on multiple factors such as treatment cost and lethality of the condition. Dr. Krause proposes mechanisms that do not allow damaging decisions once you have settled on a definition of what "damaging" means in context of the training.
%\cite{https://arxiv.org/abs/1602.04450}%
We think this is very relevant to the field of medical diagnostics and so a good improvement to consider in the future.
